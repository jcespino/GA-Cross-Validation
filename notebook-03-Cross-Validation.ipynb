{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completing the Workflow\n",
    "\n",
    "- Load and prepare data\n",
    "- Split train and test sets\n",
    "- Build the model\n",
    " - Addition of Cross Validation\n",
    "- Tune the Parameters\n",
    " - Add `GridSearchCV`\n",
    "- Reflect on the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikeshare = pd.read_csv('data/bikeshare.csv')\n",
    "weather = pd.get_dummies(bikeshare.weathersit, prefix='weather')\n",
    "\n",
    "\n",
    "modeldata = bikeshare[['temp', 'hum']].join(weather[['weather_1', 'weather_2', 'weather_3']])\n",
    "y = bikeshare.casual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train-test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(modeldata, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.78627724056598"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate, fit, and evaluate the model\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "predictions = lm.predict(X_train)\n",
    "mse = mean_squared_error(y_train, predictions)\n",
    "\n",
    "np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "Rather than using a single training set, we can iterate through a number of splits of the larger training set itself. One approach is called K-folds, where we take a separate fold each time through.  For example, if we perform a cross-validation with 5 folds, we would split the training data 5 times, each time fitting and evaluating a model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lm, X_train, y_train, scoring = \"neg_mean_squared_error\", cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40.19954311, 40.73731378, 43.32350538, 41.00108099, 38.6145071 ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.77519007065239"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5196244631240068"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = cross_validation.KFold(len(modeldata), n_folds = 5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ CROSS VALIDATION each fold ~~~~\n",
      "Model 1\n",
      "MSE: 1754.7045797988867\n",
      "R2: 0.31188643384642\n",
      "Model 2\n",
      "MSE: 1767.3528941413747\n",
      "R2: 0.31188966283358266\n",
      "Model 3\n",
      "MSE: 1465.3852307219188\n",
      "R2: 0.3117009152440636\n",
      "Model 4\n",
      "MSE: 1580.3106085711643\n",
      "R2: 0.31192485666305736\n",
      "Model 5\n",
      "MSE: 1803.0062403519232\n",
      "R2: 0.3119135551998975\n",
      "~~~~ SUMMARY OF CROSS VALIDATION ~~~~\n",
      "Mean of MSE for all folds: 1674.1519107170534\n",
      "Mean of R2 for all folds: 0.3118630847574042\n"
     ]
    }
   ],
   "source": [
    "mse_values = []\n",
    "scores = []\n",
    "n= 0\n",
    "print( \"~~~~ CROSS VALIDATION each fold ~~~~\")\n",
    "for train_index, test_index in kf:\n",
    "    lm = LinearRegression().fit(modeldata.iloc[train_index], y.iloc[train_index])\n",
    "    mse_values.append(mean_squared_error(y.iloc[test_index], lm.predict(modeldata.iloc[test_index])))\n",
    "    scores.append(lm.score(modeldata, y))\n",
    "    n+=1\n",
    "    print( 'Model', n)\n",
    "    print( 'MSE:', mse_values[n-1])\n",
    "    print( 'R2:', scores[n-1])\n",
    "\n",
    "print( \"~~~~ SUMMARY OF CROSS VALIDATION ~~~~\")\n",
    "print( 'Mean of MSE for all folds:', np.mean(mse_values))\n",
    "print( 'Mean of R2 for all folds:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "Now, suppose we are using our regularized methods here.  We want to be able to also experiment with parameters and determine something like our ideal value for $\\alpha$ in the `Ridge()` model.  We can feed a list of values to the `GridSearchCV` and it will run through the possible combinations of these using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'alpha': [alpha for alpha in [1, 5, 10, 40]],\n",
    "    'fit_intercept': [True, False]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "grid = GridSearchCV(ridge, param_grid, cv = 5, scoring = 'neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [1, 5, 10, 40], 'fit_intercept': [True, False]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(modeldata, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Fit and Parameters\n",
    "\n",
    "Now, we can investigate the model performance.  The `best_params_` will give us the ideal parameters from the search, `best_estimator_` gives the full model information, and `cv_results_` will give us full information including performance for each individual model attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 40, 'fit_intercept': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=40, copy_X=True, fit_intercept=False, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = zip(results['mean_test_score'], results['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.19907472429994 {'alpha': 1, 'fit_intercept': True}\n",
      "42.206081583932566 {'alpha': 1, 'fit_intercept': False}\n",
      "42.18885870516342 {'alpha': 5, 'fit_intercept': True}\n",
      "42.18488903631506 {'alpha': 5, 'fit_intercept': False}\n",
      "42.177685282479935 {'alpha': 10, 'fit_intercept': True}\n",
      "42.162559420472945 {'alpha': 10, 'fit_intercept': False}\n",
      "42.15168131166849 {'alpha': 40, 'fit_intercept': True}\n",
      "42.10058388779278 {'alpha': 40, 'fit_intercept': False}\n"
     ]
    }
   ],
   "source": [
    "for mean_score, param in results:\n",
    "    print(np.sqrt(-mean_score), param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split, Search, Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(modeldata, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [1, 5, 10, 40], 'fit_intercept': [True, False]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.98472272735398 {'alpha': 1, 'fit_intercept': True}\n",
      "40.993051745843275 {'alpha': 1, 'fit_intercept': False}\n",
      "40.98670862275685 {'alpha': 5, 'fit_intercept': True}\n",
      "40.99515030170469 {'alpha': 5, 'fit_intercept': False}\n",
      "40.99117397282172 {'alpha': 10, 'fit_intercept': True}\n",
      "41.0014927424939 {'alpha': 10, 'fit_intercept': False}\n",
      "41.06618466313504 {'alpha': 40, 'fit_intercept': True}\n",
      "41.100071639455365 {'alpha': 40, 'fit_intercept': False}\n"
     ]
    }
   ],
   "source": [
    "#Examine results\n",
    "results = grid.cv_results_\n",
    "results = zip(results['mean_test_score'], results['params'])\n",
    "for mean_score, param in results:\n",
    "    print(np.sqrt(-mean_score), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "   normalize=False, random_state=None, solver='auto', tol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3130531123834813"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.65424810846637"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California Housing\n",
    "\n",
    "The dataset comes from sklearn's dataset library.  We want to perform an end to end modeling project where we predict the median house value in a district.  You should follow a workflow similar to what we've encountered to this point, and may go something like:\n",
    "\n",
    "- Investigate variable types and distributions\n",
    "- Transformations?\n",
    "- Collinearity?\n",
    "- New Features?\n",
    " - Perhaps something like Rooms per Household, Bedrooms per Room, Population per Household\n",
    "- Missing Values?\n",
    " - Examine total bedrooms; drop the districts, delete the attribute, or fill values with sensible number (like median) `.fillna()`\n",
    "- Encode any Categorical Variables\n",
    "- Feature Scaling? (`MaxMinScaler` or `StandardScaler`)\n",
    "- Prepare numerical data\n",
    "- Split Train and Test Set\n",
    "- Use Cross Validation and Grid Search to explore models on training set\n",
    "- Determine best model and evaluate on Test set\n",
    "- Communicate your results including a visualization of the locations of the houses, colored by their median house value and sized by population (`plt.scatter`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_houses = pd.read_csv('data/cali_housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 11 columns):\n",
      "Unnamed: 0            20640 non-null int64\n",
      "longitude             20640 non-null float64\n",
      "latitude              20640 non-null float64\n",
      "housing_median_age    20640 non-null float64\n",
      "total_rooms           20640 non-null float64\n",
      "total_bedrooms        20433 non-null float64\n",
      "population            20640 non-null float64\n",
      "households            20640 non-null float64\n",
      "median_income         20640 non-null float64\n",
      "median_house_value    20640 non-null float64\n",
      "ocean_proximity       20640 non-null object\n",
      "dtypes: float64(9), int64(1), object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "cali_houses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_houses = cali_houses.fillna(cali_houses.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_houses['bed_something'] = cali_houses['total_rooms'] * cali_houses['total_bedrooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 12 columns):\n",
      "Unnamed: 0            20640 non-null int64\n",
      "longitude             20640 non-null float64\n",
      "latitude              20640 non-null float64\n",
      "housing_median_age    20640 non-null float64\n",
      "total_rooms           20640 non-null float64\n",
      "total_bedrooms        20640 non-null float64\n",
      "population            20640 non-null float64\n",
      "households            20640 non-null float64\n",
      "median_income         20640 non-null float64\n",
      "median_house_value    20640 non-null float64\n",
      "ocean_proximity       20640 non-null object\n",
      "bed_something         20640 non-null float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "cali_houses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
