{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completing the Workflow\n",
    "\n",
    "- Load and prepare data\n",
    "- Split train and test sets\n",
    "- Build the model\n",
    " - Addition of Cross Validation\n",
    "- Tune the Parameters\n",
    " - Add `GridSearchCV`\n",
    "- Reflect on the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikeshare = pd.read_csv('data/bikeshare.csv')\n",
    "weather = pd.get_dummies(bikeshare.weathersit, prefix='weather')\n",
    "\n",
    "\n",
    "modeldata = bikeshare[['temp', 'hum']].join(weather[['weather_1', 'weather_2', 'weather_3']])\n",
    "y = bikeshare.casual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train-test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate, fit, and evaluate the model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "Rather than using a single training set, we can iterate through a number of splits of the larger training set itself. One approach is called K-folds, where we take a separate fold each time through.  For example, if we perform a cross-validation with 5 folds, we would split the training data 5 times, each time fitting and evaluating a model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lm, modeldata, y, scoring = \"neg_mean_squared_error\", cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38.17550295, 45.07309253, 35.58704297, 69.43371546, 56.6001007 ])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.11277828232687"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.627064849219837"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = cross_validation.KFold(len(modeldata), n_folds = 5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ CROSS VALIDATION each fold ~~~~\n",
      "Model 1\n",
      "MSE: 1705.2033037910232\n",
      "R2: 0.31190233073841744\n",
      "Model 2\n",
      "MSE: 1631.8360098639637\n",
      "R2: 0.3119241721003434\n",
      "Model 3\n",
      "MSE: 1731.4021669007136\n",
      "R2: 0.31191900862279376\n",
      "Model 4\n",
      "MSE: 1586.1711382052615\n",
      "R2: 0.31188912818902204\n",
      "Model 5\n",
      "MSE: 1711.5132782226212\n",
      "R2: 0.3118918806170695\n",
      "~~~~ SUMMARY OF CROSS VALIDATION ~~~~\n",
      "Mean of MSE for all folds: 1673.2251793967166\n",
      "Mean of R2 for all folds: 0.31190530405352923\n"
     ]
    }
   ],
   "source": [
    "mse_values = []\n",
    "scores = []\n",
    "n= 0\n",
    "print( \"~~~~ CROSS VALIDATION each fold ~~~~\")\n",
    "for train_index, test_index in kf:\n",
    "    lm = LinearRegression().fit(modeldata.iloc[train_index], y.iloc[train_index])\n",
    "    mse_values.append(mean_squared_error(y.iloc[test_index], lm.predict(modeldata.iloc[test_index])))\n",
    "    scores.append(lm.score(modeldata, y))\n",
    "    n+=1\n",
    "    print( 'Model', n)\n",
    "    print( 'MSE:', mse_values[n-1])\n",
    "    print( 'R2:', scores[n-1])\n",
    "\n",
    "print( \"~~~~ SUMMARY OF CROSS VALIDATION ~~~~\")\n",
    "print( 'Mean of MSE for all folds:', np.mean(mse_values))\n",
    "print( 'Mean of R2 for all folds:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "Now, suppose we are using our regularized methods here.  We want to be able to also experiment with parameters and determine something like our ideal value for $\\alpha$ in the `Ridge()` model.  We can feed a list of values to the `GridSearchCV` and it will run through the possible combinations of these using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'alpha': [alpha for alpha in [1, 5, 10, 40]],\n",
    "    'fit_intercept': [True, False]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "grid = GridSearchCV(ridge, param_grid, cv = 5, scoring = 'neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [1, 5, 10, 40], 'fit_intercept': [True, False]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(modeldata, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Fit and Parameters\n",
    "\n",
    "Now, we can investigate the model performance.  The `best_params_` will give us the ideal parameters from the search, `best_estimator_` gives the full model information, and `cv_results_` will give us full information including performance for each individual model attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 40, 'fit_intercept': False}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=40, copy_X=True, fit_intercept=False, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = zip(results['mean_test_score'], results['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.19907472429994 {'alpha': 1, 'fit_intercept': True}\n",
      "42.206081583932566 {'alpha': 1, 'fit_intercept': False}\n",
      "42.18885870516342 {'alpha': 5, 'fit_intercept': True}\n",
      "42.18488903631506 {'alpha': 5, 'fit_intercept': False}\n",
      "42.177685282479935 {'alpha': 10, 'fit_intercept': True}\n",
      "42.162559420472945 {'alpha': 10, 'fit_intercept': False}\n",
      "42.15168131166849 {'alpha': 40, 'fit_intercept': True}\n",
      "42.10058388779278 {'alpha': 40, 'fit_intercept': False}\n"
     ]
    }
   ],
   "source": [
    "for mean_score, param in results:\n",
    "    print(np.sqrt(-mean_score), param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split, Search, Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(modeldata, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [1, 5, 10, 40], 'fit_intercept': [True, False]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.00086619515355 {'alpha': 1, 'fit_intercept': True}\n",
      "41.00615249220171 {'alpha': 1, 'fit_intercept': False}\n",
      "41.002529715157365 {'alpha': 5, 'fit_intercept': True}\n",
      "41.00825503357845 {'alpha': 5, 'fit_intercept': False}\n",
      "41.006906030024126 {'alpha': 10, 'fit_intercept': True}\n",
      "41.01467141911244 {'alpha': 10, 'fit_intercept': False}\n",
      "41.082147559583596 {'alpha': 40, 'fit_intercept': True}\n",
      "41.11453764421828 {'alpha': 40, 'fit_intercept': False}\n"
     ]
    }
   ],
   "source": [
    "#Examine results\n",
    "results = grid.cv_results_\n",
    "results = zip(results['mean_test_score'], results['params'])\n",
    "for mean_score, param in results:\n",
    "    print(np.sqrt(-mean_score), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "   normalize=False, random_state=None, solver='auto', tol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3150800266831697"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.65759825178781"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California Housing\n",
    "\n",
    "The dataset comes from sklearn's dataset library.  We want to perform an end to end modeling project where we predict the median house value in a district.  You should follow a workflow similar to what we've encountered to this point, and may go something like:\n",
    "\n",
    "- Investigate variable types and distributions\n",
    "- Transformations?\n",
    "- Collinearity?\n",
    "- New Features?\n",
    " - Perhaps something like Rooms per Household, Bedrooms per Room, Population per Household\n",
    "- Missing Values?\n",
    " - Examine total bedrooms; drop the districts, delete the attribute, or fill values with sensible number (like median) `.fillna()`\n",
    "- Encode any Categorical Variables\n",
    "- Feature Scaling? (`MaxMinScaler` or `StandardScaler`)\n",
    "- Prepare numerical data\n",
    "- Split Train and Test Set\n",
    "- Use Cross Validation and Grid Search to explore models on training set\n",
    "- Determine best model and evaluate on Test set\n",
    "- Communicate your results including a visualization of the locations of the houses, colored by their median house value and sized by population (`plt.scatter`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_houses = pd.read_csv('data/cali_housing.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
