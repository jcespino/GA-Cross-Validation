{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Below, we have a simple dataset dealing with mammalian sleep time.  \n",
    "\n",
    "```\n",
    "This is an updated and expanded version of the mammals sleep dataset. Updated sleep times and weights were taken from V. M. Savage and G. B. West. A quantitative, theoretical framework for understanding mammalian sleep. Proceedings of the National Academy of Sciences, 104 (3):1051-1056, 2007.\n",
    "```\n",
    "\n",
    "Let's use this to examine the relationship between brain and bodyweight in these critters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critters = pd.read_csv('data/mammals.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critters.plot('bodywt', 'brainwt', kind = 'scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 4))\n",
    "plt.subplot(131)\n",
    "\n",
    "plt.scatter(critters.bodywt, critters.brainwt)\n",
    "plt.subplot(132)\n",
    "plt.hist(critters.bodywt)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.hist(critters.brainwt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critters['log_bodywt'] = np.log(critters.bodywt)\n",
    "critters['log_brainwt'] = np.log(critters.brainwt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 4))\n",
    "plt.subplot(131)\n",
    "\n",
    "plt.scatter(critters.log_bodywt, critters.log_brainwt)\n",
    "plt.subplot(132)\n",
    "plt.hist(critters.log_bodywt)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.hist(critters.log_brainwt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar Model\n",
    "\n",
    "Use the code below as a starting place to examine additional correlations between the dependent variables `sleep_rem` and `awake`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_columns = ['bodywt', 'brainwt',]  # add other relationships in need of transformation\n",
    "log_critters = critters.copy()\n",
    "log_critters[log_columns] = log_critters[log_columns].apply(np.log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciKitLearn Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_selection\n",
    "\n",
    "\n",
    "lm = LinearRegression()\n",
    "X = critters.log_bodywt.values.reshape(-1,1)\n",
    "y = critters.log_brainwt\n",
    "lm.fit(X, y)\n",
    "\n",
    "pvals = feature_selection.f_regression(X, y)[1]\n",
    "predictions = lm.predict(X)\n",
    "coefficients = lm.coef_\n",
    "y_int = lm.intercept_\n",
    "r2 = lm.score(X, y)\n",
    "print('P-Values: ',pvals)\n",
    "print('Coefficients: ', coefficients)\n",
    "print('Intercept: ', y_int)\n",
    "print('R2 Score: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "plt.subplot(121)\n",
    "plt.scatter(critters.log_bodywt, critters.log_brainwt)\n",
    "plt.plot(critters.log_bodywt, predictions)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(predictions - critters.log_brainwt)\n",
    "print('R2 Score: {:.4f}'.format(lm.score(X, y)))\n",
    "print('RMSE: {:.4f}'.format(np.sqrt(mean_squared_error(X, y))))\n",
    "skew = pd.DataFrame([i for i in (predictions - critters.log_brainwt)]).skew()\n",
    "print('Residual Skew: ', skew, '\\nPvalues : ',pvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modularizing the Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_model_metrics(X, y, algo):\n",
    "    pvals = feature_selection.f_regression(X, y)[1]\n",
    "    algo.fit(X, y)\n",
    "    predictions = lm.predict(X)\n",
    "    coefficients = lm.coef_\n",
    "    y_int = lm.intercept_\n",
    "    r2 = lm.score(X, y)\n",
    "    residuals = (y - predictions)\n",
    "    print('P-Values: ',pvals)\n",
    "    print('Coefficients: ', coefficients)\n",
    "    print('Intercept: ', y_int)\n",
    "    print('R2 Score: ', r2)\n",
    "    plt.hist(residuals)\n",
    "    return algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "get_linear_model_metrics(X = X, y = y, algo = lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.predict(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression(fit_intercept=False)\n",
    "X = critters.log_bodywt.values.reshape(-1,1)\n",
    "y = critters.log_brainwt\n",
    "lm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.predict(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "plt.subplot(121)\n",
    "plt.scatter(critters.log_bodywt, critters.log_brainwt)\n",
    "plt.plot(critters.log_bodywt, predictions)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(predictions2 - critters.log_brainwt)\n",
    "print('R2 Score: {:.4f}'.format(lm.score(X, y)))\n",
    "print('RMSE: {:.4f}'.format(np.sqrt(mean_squared_error(X, y))))\n",
    "skew = pd.DataFrame([i for i in (predictions2 - critters.log_brainwt)]).skew()\n",
    "print('Residual Skew: ', skew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `LinearRegression`\n",
    "\n",
    "We have now seen that the data in its earliest state did not allow fo the best linear regression fit.  Attempt to generate two more models using the log-transformed data to see how this changes the model's performance.  Update X and y to match the log-transformed data and add True and False to the loop so we examine each scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =\n",
    "y =\n",
    "loop = []\n",
    "for boolean in loop:\n",
    "    print 'y-intercept:', boolean\n",
    "    lm = LinearRegression(fit_intercept=boolean)\n",
    "    get_linear_model_metrics(X, y, lm)\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Regression Classes\n",
    "\n",
    "Compare the earlier model to implementations of the `Lasso, Ridge` and `ElasticNet` regularized models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "ridge = Ridge()\n",
    "enet = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CitiBike Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = pd.read_csv('data/bikeshare.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(bikes[['temp', 'atemp', 'casual']]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = bikes[['temp', 'atemp', 'casual']].corr()\n",
    "print(correlations)\n",
    "sns.heatmap(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bikes['casual']\n",
    "x_sets = (\n",
    "    ['temp'],\n",
    "    ['atemp'],\n",
    "    ['temp', 'atemp'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in x_sets:\n",
    "    lm.fit(bikes[x], y)\n",
    "    print('Score for ', x, '{:.3f}'.format(lm.score(bikes[x], y)), '\\ncoefficients', lm.coef_, '\\n')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the 2-variable model temp + atemp has a higher explanation of variance than two variables on their own, and both variables are considered significant (p values approaching 0), we can see that together, their coefficients are wildly different. This can introduce error in how we explain models.\n",
    "\n",
    "What happens if we use a second variable that isn't highly correlated with temperature, like humidity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity with dummy variables\n",
    "\n",
    "\n",
    "There can be a similar effect from a feature set that is a singular matrix, which is when there is a clear relationship in the matrix (for example, the sum of all rows = 1).\n",
    "\n",
    "Run through the following code on your own. What happens to the coefficients when you include all weather situations instead of just including all except one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "weather = pd.get_dummies(bikes.weathersit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(weather, y)\n",
    "print(lm.score(weather, y))\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(weather[[1, 2, 3]], y)\n",
    "print(lm.score(weather[[1, 2, 3]], y))\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "\n",
    "1. Add the dummy variables for the weather situations to the DataFrame.  \n",
    "2. Find at least two additional features that are not correlated with current features but could be strong indicators for predicting guest riders.\n",
    "3. Fit a model to these features, describe the results.\n",
    "\n",
    "---\n",
    "\n",
    "**Extra**\n",
    "\n",
    "Generate your model using a `train_test_split`, and evaluate it on the test set.\n",
    "\n",
    "Do this five times and determine the quality of the average of these models.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
